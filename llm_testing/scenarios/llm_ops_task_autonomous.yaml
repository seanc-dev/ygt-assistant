name: llm_ops_task_autonomous
mode: mock
steps:
  - action: reset_state
  - action: http
    method: POST
    url: /dev/workroom/seed
    expect:
      status: 200
  - action: http
    method: PUT
    url: /api/settings
    json:
      trust_level: "autonomous"
    expect:
      status: 200
  - action: http
    method: GET
    url: /api/workroom/tree
    expect:
      status: 200
    extract:
      task_id: "tree.0.children.0.id"
  - action: http
    method: POST
    url: /api/workroom/tasks/<task_id>/assistant-suggest
    json:
      message: "Update this task status to doing and create a follow-up task"
    expect:
      status: 200
      contains:
        - "operations"
        - "applied"
expectations:
  must_contain:
    - "operations"
    - "applied"
  must_not_contain:
    - "error"
  function_calling:
    # Assess that LLM correctly generates operations
    check_operations: true
    # In autonomous mode, operations should be applied directly
    expected_behavior: "operations_should_be_applied"
    # Snapshot operation responses (deterministic - generated by our code, not LLM)
    snapshot_operations: "llm_ops_task_autonomous_operations.json"
